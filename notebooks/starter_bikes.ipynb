{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "starter_bikes.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "mA0HPVmIBT4C",
        "outputId": "ff6adbed-392d-40e0-d5d8-8fecfcdb54e6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the training dataset\n",
        "data_url = \"https://raw.githubusercontent.com/byui-cse/cse450-course/master/data/bikes.csv\"\n",
        "data = pd.read_csv(data_url)\n",
        "\n",
        "# Load the mini holdout dataset\n",
        "mini_holdout_url = \"https://raw.githubusercontent.com/byui-cse/cse450-course/master/data/biking_holdout_test_mini.csv\"\n",
        "mini_holdout = pd.read_csv(mini_holdout_url)\n",
        "\n",
        "# Inspect the datasets\n",
        "print(\"Training Dataset:\")\n",
        "print(data.head())\n",
        "print(\"\\nMini Holdout Dataset:\")\n",
        "print(mini_holdout.head())\n",
        "\n",
        "# Check column names\n",
        "print(\"\\nColumns in Training Dataset:\", data.columns)\n",
        "print(\"Columns in Mini Holdout Dataset:\", mini_holdout.columns)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Dataset:\n",
            "     dteday   hr  casual  registered  temp_c  feels_like_c     hum  windspeed  \\\n",
            "0  1/1/2011  0.0       3          13     3.0           3.0  0.7957        0.8   \n",
            "1  1/1/2011  1.0       8          30     1.7           1.7  0.8272        0.8   \n",
            "2  1/1/2011  2.0       5          26     1.9           1.9  0.8157        1.1   \n",
            "3  1/1/2011  3.0       3           9     2.5           2.5  0.7831        0.8   \n",
            "4  1/1/2011  4.0       0           1     2.0           2.0  0.8075        1.1   \n",
            "\n",
            "   weathersit  season  holiday  workingday  \n",
            "0           1       1        0           0  \n",
            "1           1       1        0           0  \n",
            "2           1       1        0           0  \n",
            "3           1       1        0           0  \n",
            "4           1       1        0           0  \n",
            "\n",
            "Mini Holdout Dataset:\n",
            "       dteday   hr  temp_c  feels_like_c     hum  windspeed  weathersit  \\\n",
            "0  11/15/2023  0.0     7.3           7.3  0.6667        0.0           1   \n",
            "1  11/15/2023  1.0     6.2           6.2  0.7406        0.0           1   \n",
            "2  11/15/2023  2.0     5.2           3.2  0.8232        8.5           1   \n",
            "3  11/15/2023  3.0     5.7           3.6  0.7573        9.4           2   \n",
            "4  11/15/2023  4.0     5.2           2.9  0.7918       10.1           2   \n",
            "\n",
            "   season  holiday  workingday  \n",
            "0       4        0           1  \n",
            "1       4        0           1  \n",
            "2       4        0           1  \n",
            "3       4        0           1  \n",
            "4       4        0           1  \n",
            "\n",
            "Columns in Training Dataset: Index(['dteday', 'hr', 'casual', 'registered', 'temp_c', 'feels_like_c', 'hum',\n",
            "       'windspeed', 'weathersit', 'season', 'holiday', 'workingday'],\n",
            "      dtype='object')\n",
            "Columns in Mini Holdout Dataset: Index(['dteday', 'hr', 'temp_c', 'feels_like_c', 'hum', 'windspeed',\n",
            "       'weathersit', 'season', 'holiday', 'workingday'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add the 'count' column to the training dataset\n",
        "data['count'] = data['casual'] + data['registered']\n",
        "\n",
        "# Drop the 'casual' and 'registered' columns since they are no longer needed\n",
        "data = data.drop(columns=['casual', 'registered'])\n",
        "\n",
        "# Verify the new column\n",
        "print(\"\\nTraining Dataset with 'count':\")\n",
        "print(data.head())"
      ],
      "metadata": {
        "id": "43kH3B9NMdEb",
        "outputId": "fa638298-712d-4278-c303-b59c5ea2750e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training Dataset with 'count':\n",
            "     dteday   hr  temp_c  feels_like_c     hum  windspeed  weathersit  season  \\\n",
            "0  1/1/2011  0.0     3.0           3.0  0.7957        0.8           1       1   \n",
            "1  1/1/2011  1.0     1.7           1.7  0.8272        0.8           1       1   \n",
            "2  1/1/2011  2.0     1.9           1.9  0.8157        1.1           1       1   \n",
            "3  1/1/2011  3.0     2.5           2.5  0.7831        0.8           1       1   \n",
            "4  1/1/2011  4.0     2.0           2.0  0.8075        1.1           1       1   \n",
            "\n",
            "   holiday  workingday  count  \n",
            "0        0           0     16  \n",
            "1        0           0     38  \n",
            "2        0           0     31  \n",
            "3        0           0     12  \n",
            "4        0           0      1  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert 'dteday' to datetime format\n",
        "data['dteday'] = pd.to_datetime(data['dteday'])\n",
        "\n",
        "# Extract temporal features\n",
        "data['month'] = data['dteday'].dt.month\n",
        "data['day_of_week'] = data['dteday'].dt.dayofweek\n",
        "data['is_weekend'] = data['day_of_week'].isin([5, 6]).astype(int)\n",
        "\n",
        "# Drop 'dteday' after extracting features\n",
        "data = data.drop(columns=['dteday'])"
      ],
      "metadata": {
        "id": "kWI6BCnMMf9w"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# Identify categorical features\n",
        "categorical_features = ['season', 'weathersit']\n",
        "\n",
        "# Initialize the encoder\n",
        "encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
        "\n",
        "# Fit and transform the categorical features\n",
        "encoded_features = encoder.fit_transform(data[categorical_features])\n",
        "\n",
        "# Convert to DataFrame and append to the dataset\n",
        "encoded_columns = encoder.get_feature_names_out(categorical_features)\n",
        "encoded_df = pd.DataFrame(encoded_features, columns=encoded_columns)\n",
        "data = pd.concat([data.drop(columns=categorical_features), encoded_df], axis=1)"
      ],
      "metadata": {
        "id": "uBdaS_POMiNu"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Identify numerical features\n",
        "numerical_features = ['hr', 'temp_c', 'feels_like_c', 'hum', 'windspeed', 'month', 'day_of_week', 'is_weekend']\n",
        "\n",
        "# Initialize the scaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit and transform the numerical features\n",
        "data[numerical_features] = scaler.fit_transform(data[numerical_features])"
      ],
      "metadata": {
        "id": "JZyHnKt3MmVf"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Define features (X) and target (y)\n",
        "X = data.drop(columns=['count'], errors='ignore')  # Features (all columns except 'count')\n",
        "y = data['count']  # Target variable\n",
        "\n",
        "# Split into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Verify the shapes of the splits\n",
        "print(\"\\nX_train shape:\", X_train.shape)\n",
        "print(\"X_val shape:\", X_val.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"y_val shape:\", y_val.shape)"
      ],
      "metadata": {
        "id": "WzFOwK43Monh",
        "outputId": "e0983b3f-c299-493c-bf14-5128481f7299",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "X_train shape: (89980, 18)\n",
            "X_val shape: (22495, 18)\n",
            "y_train shape: (89980,)\n",
            "y_val shape: (22495,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "\n",
        "# Build the neural network\n",
        "model = Sequential([\n",
        "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    Dropout(0.2),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    Dense(1)  # Output layer for regression\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=50,\n",
        "    batch_size=32,\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "id": "fqFYzL-yMugv",
        "outputId": "011202ec-4e07-4ab4-f480-836703f654c7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2812/2812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 113215.6016 - mae: 231.7284 - val_loss: 73636.0781 - val_mae: 192.9909\n",
            "Epoch 2/50\n",
            "\u001b[1m2812/2812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 77699.9844 - mae: 199.8164 - val_loss: 71885.7969 - val_mae: 191.7579\n",
            "Epoch 3/50\n",
            "\u001b[1m2812/2812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 71533.8203 - mae: 187.9653 - val_loss: 54286.4648 - val_mae: 156.8385\n",
            "Epoch 4/50\n",
            "\u001b[1m2812/2812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 59421.4766 - mae: 167.9650 - val_loss: 48963.0117 - val_mae: 141.7675\n",
            "Epoch 5/50\n",
            "\u001b[1m2812/2812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 56198.6836 - mae: 162.9470 - val_loss: 46102.5352 - val_mae: 133.1557\n",
            "Epoch 6/50\n",
            "\u001b[1m2812/2812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 53646.4492 - mae: 158.6769 - val_loss: 43928.5742 - val_mae: 132.0983\n",
            "Epoch 7/50\n",
            "\u001b[1m2812/2812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 52346.6250 - mae: 156.9872 - val_loss: 43019.0195 - val_mae: 128.4613\n",
            "Epoch 8/50\n",
            "\u001b[1m2812/2812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 51760.6055 - mae: 156.1848 - val_loss: 42332.6406 - val_mae: 128.6826\n",
            "Epoch 9/50\n",
            "\u001b[1m2812/2812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 51138.9336 - mae: 155.5974 - val_loss: 41280.3711 - val_mae: 127.4789\n",
            "Epoch 10/50\n",
            "\u001b[1m2812/2812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 50995.4258 - mae: 155.1261 - val_loss: 40712.7969 - val_mae: 126.5868\n",
            "Epoch 11/50\n",
            "\u001b[1m2812/2812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - loss: 49740.1953 - mae: 153.4922 - val_loss: 39886.7266 - val_mae: 126.5114\n",
            "Epoch 12/50\n",
            "\u001b[1m2812/2812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 49840.5820 - mae: 153.6592 - val_loss: 39503.9336 - val_mae: 123.8757\n",
            "Epoch 13/50\n",
            "\u001b[1m2812/2812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 49551.8086 - mae: 153.0340 - val_loss: 39420.4727 - val_mae: 125.8836\n",
            "Epoch 14/50\n",
            "\u001b[1m2812/2812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 48953.5391 - mae: 151.9332 - val_loss: 39140.6953 - val_mae: 127.6517\n",
            "Epoch 15/50\n",
            "\u001b[1m2812/2812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 49055.9727 - mae: 151.7219 - val_loss: 39072.4727 - val_mae: 123.5569\n",
            "Epoch 16/50\n",
            "\u001b[1m2812/2812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 48645.7422 - mae: 150.8100 - val_loss: 39144.7461 - val_mae: 129.3952\n",
            "Epoch 17/50\n",
            "\u001b[1m2812/2812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 48729.6289 - mae: 151.5915 - val_loss: 38158.7422 - val_mae: 121.7669\n",
            "Epoch 18/50\n",
            "\u001b[1m2812/2812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - loss: 48099.7461 - mae: 150.1128 - val_loss: 37540.1719 - val_mae: 126.3190\n",
            "Epoch 19/50\n",
            "\u001b[1m2812/2812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 47601.9609 - mae: 149.9872 - val_loss: 36847.0156 - val_mae: 120.0800\n",
            "Epoch 20/50\n",
            "\u001b[1m2812/2812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 47767.8242 - mae: 149.5390 - val_loss: 35902.1211 - val_mae: 119.7873\n",
            "Epoch 21/50\n",
            "\u001b[1m2812/2812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 46812.3789 - mae: 148.4448 - val_loss: 35488.8125 - val_mae: 118.8917\n",
            "Epoch 22/50\n",
            "\u001b[1m2812/2812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 45712.2070 - mae: 146.4298 - val_loss: 34981.1328 - val_mae: 119.9143\n",
            "Epoch 23/50\n",
            "\u001b[1m2812/2812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 46081.1250 - mae: 146.8503 - val_loss: 34676.2070 - val_mae: 119.1197\n",
            "Epoch 24/50\n",
            "\u001b[1m2812/2812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 45161.3164 - mae: 145.4218 - val_loss: 33941.1758 - val_mae: 116.6170\n",
            "Epoch 25/50\n",
            "\u001b[1m2812/2812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 45461.0586 - mae: 145.0406 - val_loss: 33806.9492 - val_mae: 116.2764\n",
            "Epoch 26/50\n",
            "\u001b[1m2812/2812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 44768.7695 - mae: 144.8141 - val_loss: 33832.5352 - val_mae: 115.2004\n",
            "Epoch 27/50\n",
            "\u001b[1m2812/2812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 44672.9375 - mae: 143.6080 - val_loss: 33259.5430 - val_mae: 116.8909\n",
            "Epoch 28/50\n",
            "\u001b[1m2812/2812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 43949.2617 - mae: 143.2240 - val_loss: 32534.2090 - val_mae: 115.7115\n",
            "Epoch 29/50\n",
            "\u001b[1m2812/2812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 43408.8008 - mae: 142.1321 - val_loss: 31989.1914 - val_mae: 111.9625\n",
            "Epoch 30/50\n",
            "\u001b[1m2812/2812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 43115.5781 - mae: 141.3795 - val_loss: 32063.1582 - val_mae: 114.6939\n",
            "Epoch 31/50\n",
            "\u001b[1m2812/2812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 43280.2305 - mae: 141.3500 - val_loss: 32631.1289 - val_mae: 114.5202\n",
            "Epoch 32/50\n",
            "\u001b[1m2812/2812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 42622.9180 - mae: 140.6397 - val_loss: 31785.1543 - val_mae: 113.7493\n",
            "Epoch 33/50\n",
            "\u001b[1m2812/2812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 42684.3516 - mae: 140.3252 - val_loss: 31712.4141 - val_mae: 114.4539\n",
            "Epoch 34/50\n",
            "\u001b[1m2812/2812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 42160.0781 - mae: 139.1576 - val_loss: 31817.0293 - val_mae: 113.0342\n",
            "Epoch 35/50\n",
            "\u001b[1m2812/2812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 42467.2891 - mae: 139.2959 - val_loss: 32090.5254 - val_mae: 113.6178\n",
            "Epoch 36/50\n",
            "\u001b[1m2812/2812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 42643.4766 - mae: 139.7999 - val_loss: 32095.4121 - val_mae: 112.3451\n",
            "Epoch 37/50\n",
            "\u001b[1m2812/2812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 42000.4258 - mae: 138.3758 - val_loss: 31515.2129 - val_mae: 114.0624\n",
            "Epoch 38/50\n",
            "\u001b[1m2812/2812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 41808.4219 - mae: 138.3690 - val_loss: 32262.2988 - val_mae: 111.1764\n",
            "Epoch 39/50\n",
            "\u001b[1m2812/2812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 41671.2344 - mae: 138.2099 - val_loss: 31334.5176 - val_mae: 111.7159\n",
            "Epoch 40/50\n",
            "\u001b[1m2812/2812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 41174.9648 - mae: 137.5002 - val_loss: 31442.9570 - val_mae: 110.0519\n",
            "Epoch 41/50\n",
            "\u001b[1m2812/2812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 41636.2891 - mae: 137.1927 - val_loss: 31076.2129 - val_mae: 112.8441\n",
            "Epoch 42/50\n",
            "\u001b[1m2812/2812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 41072.0430 - mae: 136.8899 - val_loss: 30968.8047 - val_mae: 111.1326\n",
            "Epoch 43/50\n",
            "\u001b[1m2812/2812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 40827.8242 - mae: 136.3244 - val_loss: 30682.4004 - val_mae: 109.7323\n",
            "Epoch 44/50\n",
            "\u001b[1m2812/2812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - loss: 40904.9062 - mae: 135.9824 - val_loss: 31630.4336 - val_mae: 113.5624\n",
            "Epoch 45/50\n",
            "\u001b[1m2812/2812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 41155.3672 - mae: 136.5987 - val_loss: 30939.5312 - val_mae: 110.7269\n",
            "Epoch 46/50\n",
            "\u001b[1m2812/2812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 39994.1406 - mae: 134.7777 - val_loss: 30579.2051 - val_mae: 110.1415\n",
            "Epoch 47/50\n",
            "\u001b[1m2812/2812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 40452.2148 - mae: 134.8815 - val_loss: 30589.4629 - val_mae: 111.2253\n",
            "Epoch 48/50\n",
            "\u001b[1m2812/2812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 39789.4414 - mae: 133.6719 - val_loss: 30807.4883 - val_mae: 109.7801\n",
            "Epoch 49/50\n",
            "\u001b[1m2812/2812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 39542.6914 - mae: 133.3566 - val_loss: 30135.0957 - val_mae: 111.9220\n",
            "Epoch 50/50\n",
            "\u001b[1m2812/2812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - loss: 39918.7578 - mae: 133.2209 - val_loss: 29786.7383 - val_mae: 109.2086\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert 'dteday' to datetime format\n",
        "mini_holdout['dteday'] = pd.to_datetime(mini_holdout['dteday'])\n",
        "\n",
        "# Extract temporal features\n",
        "mini_holdout['month'] = mini_holdout['dteday'].dt.month\n",
        "mini_holdout['day_of_week'] = mini_holdout['dteday'].dt.dayofweek\n",
        "mini_holdout['is_weekend'] = mini_holdout['day_of_week'].isin([5, 6]).astype(int)\n",
        "\n",
        "# Drop 'dteday' after extracting features\n",
        "mini_holdout = mini_holdout.drop(columns=['dteday'])\n",
        "\n",
        "# One-hot encode categorical features\n",
        "encoded_features_holdout = encoder.transform(mini_holdout[categorical_features])\n",
        "encoded_df_holdout = pd.DataFrame(encoded_features_holdout, columns=encoded_columns)\n",
        "mini_holdout = pd.concat([mini_holdout.drop(columns=categorical_features), encoded_df_holdout], axis=1)\n",
        "\n",
        "# Normalize numerical features\n",
        "mini_holdout[numerical_features] = scaler.transform(mini_holdout[numerical_features])"
      ],
      "metadata": {
        "id": "WUX4EIvtOWut"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate predictions\n",
        "predicted_counts = model.predict(mini_holdout).flatten()\n",
        "predicted_counts = predicted_counts.round(0).astype(int)\n",
        "\n",
        "# Save predictions to a CSV file\n",
        "results = pd.DataFrame({'count': predicted_counts})\n",
        "results.to_csv(\"team8-bike-rental-predictions.csv\", index=False)\n",
        "\n",
        "print(\"\\nPredictions saved to team8-bike-rental-predictions.csv\")"
      ],
      "metadata": {
        "id": "3YoUVHlCOab6",
        "outputId": "2bff3ea4-2086-4be7-c2ce-abf491db928b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "\n",
            "Predictions saved to team8-bike-rental-predictions.csv\n"
          ]
        }
      ]
    }
  ]
}